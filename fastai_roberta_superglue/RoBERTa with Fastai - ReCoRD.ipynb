{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RoBERTa with Fastai - ReCoRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:11.355152Z",
     "start_time": "2020-03-02T17:17:10.313602Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.metrics import *\n",
    "from transformers import RobertaTokenizer\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:11.360217Z",
     "start_time": "2020-03-02T17:17:11.356747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a config class to store task specific information\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:11.372065Z",
     "start_time": "2020-03-02T17:17:11.361457Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining our configuration\n",
    "\n",
    "config = Config(\n",
    "    task = \"ReCoRD\",\n",
    "#     remove_percent = None, # Set to a num between 0 and 1 to remove num% from training ds (for quicker training)\n",
    "    remove_percent = .99, # Set to None if not testing other this percetage will be removed from training ds\n",
    "    undersample = True, # will fix the class imbalance by undersampling\n",
    "    seq_len_check = False, # will remove all inputs over the max seq length (as opposed to truncating them)\n",
    "    seed = 2019,\n",
    "    roberta_model_name='roberta-base', # can also be exchanged with roberta-large \n",
    "    pad_idx = 0,\n",
    "    max_lr=1e-5,\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    bs=4, \n",
    "    max_seq_len=256, \n",
    "    num_labels = 2,\n",
    "    hidden_dropout_prob=.05,\n",
    "    hidden_size=768, # 1024 for roberta-large\n",
    "    start_tok = \"<s>\",\n",
    "    end_tok = \"</s>\",\n",
    "    mask_tok = \"<mask>\",\n",
    "    mark_fields=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:11.377629Z",
     "start_time": "2020-03-02T17:17:11.373505Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(\".\")\n",
    "data_path = path/\"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:11.384483Z",
     "start_time": "2020-03-02T17:17:11.378826Z"
    }
   },
   "outputs": [],
   "source": [
    "#load json object\n",
    "def record_parser(path_to_json, test=False):\n",
    "    with jsonlines.open(path_to_json) as f:\n",
    "        idx,passage_idx,passage,question,entity,label = [],[],[],[],[],[]\n",
    "        for obj in f:\n",
    "            text = obj[\"passage\"][\"text\"]\n",
    "            for q in obj['qas']:\n",
    "                if not test: answers = [a[\"text\"] for a in q[\"answers\"]] \n",
    "                for e in obj[\"passage\"][\"entities\"]:\n",
    "                    idx.append(q[\"idx\"])\n",
    "                    passage_idx.append(obj[\"idx\"])\n",
    "                    passage.append(text)\n",
    "                    ques = q[\"query\"]#.replace(\"@placeholder\",config.mask_tok)\n",
    "                    question.append(ques)\n",
    "                    ent = text[e[\"start\"]:e[\"end\"]+1]\n",
    "                    entity.append(ent)\n",
    "                    label.append(ent in answers) if not test else label.append(None)\n",
    "    return pd.DataFrame({\"idx\":idx,\"passage_idx\":passage_idx,\"passage\":passage,\"question\":question,\"entity\":entity,\"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.925278Z",
     "start_time": "2020-03-02T17:17:11.385623Z"
    }
   },
   "outputs": [],
   "source": [
    "train = record_parser(data_path/config.task/\"train.jsonl\")\n",
    "val = record_parser(data_path/config.task/\"val.jsonl\")\n",
    "test = record_parser(data_path/config.task/\"test.jsonl\",test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.936629Z",
     "start_time": "2020-03-02T17:17:14.926527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>passage_idx</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1796851</th>\n",
       "      <td>100729</td>\n",
       "      <td>65708</td>\n",
       "      <td>By Kieran Gill Anton Ferdinand has signed for ...</td>\n",
       "      <td>Fresh start: Ferdinand will hope he gets more ...</td>\n",
       "      <td>Thai</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796852</th>\n",
       "      <td>100729</td>\n",
       "      <td>65708</td>\n",
       "      <td>By Kieran Gill Anton Ferdinand has signed for ...</td>\n",
       "      <td>Fresh start: Ferdinand will hope he gets more ...</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796853</th>\n",
       "      <td>100729</td>\n",
       "      <td>65708</td>\n",
       "      <td>By Kieran Gill Anton Ferdinand has signed for ...</td>\n",
       "      <td>Fresh start: Ferdinand will hope he gets more ...</td>\n",
       "      <td>Antalyaspor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796854</th>\n",
       "      <td>100729</td>\n",
       "      <td>65708</td>\n",
       "      <td>By Kieran Gill Anton Ferdinand has signed for ...</td>\n",
       "      <td>Fresh start: Ferdinand will hope he gets more ...</td>\n",
       "      <td>Bursaspor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796855</th>\n",
       "      <td>100729</td>\n",
       "      <td>65708</td>\n",
       "      <td>By Kieran Gill Anton Ferdinand has signed for ...</td>\n",
       "      <td>Fresh start: Ferdinand will hope he gets more ...</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idx  passage_idx  \\\n",
       "1796851  100729        65708   \n",
       "1796852  100729        65708   \n",
       "1796853  100729        65708   \n",
       "1796854  100729        65708   \n",
       "1796855  100729        65708   \n",
       "\n",
       "                                                   passage  \\\n",
       "1796851  By Kieran Gill Anton Ferdinand has signed for ...   \n",
       "1796852  By Kieran Gill Anton Ferdinand has signed for ...   \n",
       "1796853  By Kieran Gill Anton Ferdinand has signed for ...   \n",
       "1796854  By Kieran Gill Anton Ferdinand has signed for ...   \n",
       "1796855  By Kieran Gill Anton Ferdinand has signed for ...   \n",
       "\n",
       "                                                  question       entity  label  \n",
       "1796851  Fresh start: Ferdinand will hope he gets more ...         Thai  False  \n",
       "1796852  Fresh start: Ferdinand will hope he gets more ...    Ferdinand  False  \n",
       "1796853  Fresh start: Ferdinand will hope he gets more ...  Antalyaspor  False  \n",
       "1796854  Fresh start: Ferdinand will hope he gets more ...    Bursaspor  False  \n",
       "1796855  Fresh start: Ferdinand will hope he gets more ...       Turkey   True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.957118Z",
     "start_time": "2020-03-02T17:17:14.937775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The harrowing stories of women and children locked up for so-called 'moral crimes' in Afghanistan's notorious female prison have been revealed after cameras were allowed inside. Mariam has been in Badam Bagh prison for three months after she shot a man who just raped her at gunpoint and then turned the weapon on herself - but she has yet to been charged. Nuria has eight months left to serve of her sentence for trying to divorce her husband. She gave birth in prison to her son and they share a cell together. Scroll down for video Nuria was jailed for trying to divorce her husband. Her son is one of 62 children living at Badam Bagh prison\\n@highlight\\nMost of the 202 Badam Bagh inmates are jailed for so-called 'moral crimes'\\n@highlight\\nCrimes include leaving their husbands or refusing an arrange marriage\\n@highlight\\n62 children live there and share cells with their mothers and five others\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.passage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.962278Z",
     "start_time": "2020-03-02T17:17:14.959242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The baby she gave birth to is her husbands and he has even offered to have the courts set her free if she returns, but @placeholder has refused.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.question[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.982576Z",
     "start_time": "2020-03-02T17:17:14.963887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1537301\n",
       "True      259555\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.985691Z",
     "start_time": "2020-03-02T17:17:14.983723Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = [\"question\",\"passage\",\"entity\"]\n",
    "label_cols = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:14.994584Z",
     "start_time": "2020-03-02T17:17:14.986842Z"
    }
   },
   "outputs": [],
   "source": [
    "class FastAiRobertaTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n",
    "    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n",
    "        self._pretrained_tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len \n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self \n",
    "    def tokenizer(self, t:str) -> List[str]: \n",
    "        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n",
    "        if config.mark_fields:\n",
    "            sub = 2 # subtraction in totoal seq_length to be made due to adding spcl tokens\n",
    "            assert \"xxfld\" in t\n",
    "            t = t.replace(\"xxfld 1\",\"\") # remove the xxfld 1 special token from fastai\n",
    "            # converting fastai field sep token to Roberta\n",
    "            t = re.split(r'xxfld \\d+', t) \n",
    "            res = []\n",
    "            for i in range(len(t)-1): # loop over the number of additional fields and the Roberta sep\n",
    "                res += self._pretrained_tokenizer.tokenize(t[i]) + [config.end_tok]\n",
    "                sub += 1 # increase our subtractions since we added more spcl tokens\n",
    "            res += self._pretrained_tokenizer.tokenize(t[-1]) # add the last sequence\n",
    "            return [config.start_tok] + res[:self.max_seq_len - sub] + [config.end_tok] \n",
    "        \n",
    "        res = self._pretrained_tokenizer.tokenize(t)\n",
    "        return [config.start_tok] + res[:self.max_seq_len - sub] + [config.end_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:15.423833Z",
     "start_time": "2020-03-02T17:17:14.995826Z"
    }
   },
   "outputs": [],
   "source": [
    "# create fastai tokenizer for roberta\n",
    "roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n",
    "                             pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:15.545075Z",
     "start_time": "2020-03-02T17:17:15.425098Z"
    }
   },
   "outputs": [],
   "source": [
    "# create fastai vocabulary for roberta\n",
    "roberta_tok.save_vocabulary(path)\n",
    "\n",
    "with open('vocab.json', 'r') as f:\n",
    "    roberta_vocab_dict = json.load(f)\n",
    "    \n",
    "fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:15.550359Z",
     "start_time": "2020-03-02T17:17:15.546286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up pre-processors\n",
    "class RobertaTokenizeProcessor(TokenizeProcessor):\n",
    "    def __init__(self, tokenizer):\n",
    "         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False, mark_fields=config.mark_fields)\n",
    "\n",
    "class RobertaNumericalizeProcessor(NumericalizeProcessor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, vocab=fastai_roberta_vocab, **kwargs)\n",
    "\n",
    "\n",
    "def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
    "    \"\"\"\n",
    "    Constructing preprocessors for Roberta\n",
    "    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n",
    "    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n",
    "    \"\"\"\n",
    "    return [RobertaTokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(vocab=vocab)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:57:34.043098Z",
     "start_time": "2019-09-30T20:57:34.037768Z"
    }
   },
   "source": [
    "## Accounting for DF Size and Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:15.596471Z",
     "start_time": "2020-03-02T17:17:15.551359Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "def undersample(df):\n",
    "    rus = RandomUnderSampler(random_state=config.seed)\n",
    "    X_train, y_train = rus.fit_resample(df[feat_cols], df[label_cols])\n",
    "    res = pd.DataFrame(X_train)\n",
    "    res[\"label\"] = y_train\n",
    "    res.columns = df[[\"question\",\"passage\",\"entity\"]+[label_cols]].columns\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.438871Z",
     "start_time": "2020-03-02T17:17:15.597874Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.undersample: train = undersample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.520900Z",
     "start_time": "2020-03-02T17:17:16.440083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513918 of the training dataset is removed\n"
     ]
    }
   ],
   "source": [
    "# reduce df sizes if testing\n",
    "\n",
    "np.random.seed(config.seed)\n",
    "    \n",
    "if config.remove_percent: # if testing\n",
    "    print(int(train.shape[0]*config.remove_percent), \"of the training dataset is removed\")\n",
    "    \n",
    "    remove_percent = config.remove_percent\n",
    "    train_drop_indices = np.random.choice(train.index, int(train.shape[0]*remove_percent), replace=False)\n",
    "    train.drop(train_drop_indices, inplace=True)\n",
    "    \n",
    "    val_drop_indices = np.random.choice(val.index, int(val.shape[0]*remove_percent), replace=False)\n",
    "    val.drop(val_drop_indices, inplace=True)\n",
    "    \n",
    "    test_drop_indices = np.random.choice(test.index, int(test.shape[0]*remove_percent), replace=False)\n",
    "    test.drop(test_drop_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.525212Z",
     "start_time": "2020-03-02T17:17:16.522443Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_len_check(row):\n",
    "    seq_len = 1\n",
    "    for c in feat_cols:\n",
    "        seq_len += len(roberta_tok.tokenize(str(row[c]))) + 1    \n",
    "    return seq_len < (config.max_seq_len - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.538980Z",
     "start_time": "2020-03-02T17:17:16.526444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5192, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.545110Z",
     "start_time": "2020-03-02T17:17:16.540119Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if config.seq_len_check:\n",
    "    train_in_range = train.apply(seq_len_check,axis=1)\n",
    "    val_in_range = val.apply(seq_len_check,axis=1)\n",
    "    test_in_range = test.apply(seq_len_check,axis=1)\n",
    "\n",
    "    print(\"dropping {} out of {} questions in train\".format(sum(~train_in_range),len(train)))\n",
    "    print(\"dropping {} out of {} questions in val\".format(sum(~val_in_range),len(val)))\n",
    "    print(\"dropping {} out of {} questions in test\".format(sum(~test_in_range),len(test)))\n",
    "\n",
    "    train = train[train_in_range]\n",
    "    val = val[val_in_range]\n",
    "    test = test[test_in_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.557683Z",
     "start_time": "2020-03-02T17:17:16.546188Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training and val data\n",
    "train = train.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n",
    "val = val.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.567989Z",
     "start_time": "2020-03-02T17:17:16.558886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winner: @placeholder's Marco Tavares (centre) ...</td>\n",
       "      <td>By Mark Wilson for MailOnline For Callum McGre...</td>\n",
       "      <td>Maribor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Congress passed a bill banning the use of...</td>\n",
       "      <td>Editor's note: Julian E. Zelizer is a professo...</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since @placeholder, each time I go to a game -...</td>\n",
       "      <td>(CNN) -- My prized Penn State sweatshirt sits ...</td>\n",
       "      <td>Sandusky</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perez, of @placeholder, agreed that drug traff...</td>\n",
       "      <td>(CNN) -- An isolated Indian tribe in Brazil se...</td>\n",
       "      <td>National Indian Foundation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heidi said she wanted a beach wedding original...</td>\n",
       "      <td>By Katy Winter PUBLISHED: 07:05 EST, 26 Februa...</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Winner: @placeholder's Marco Tavares (centre) ...   \n",
       "1  When Congress passed a bill banning the use of...   \n",
       "2  Since @placeholder, each time I go to a game -...   \n",
       "3  Perez, of @placeholder, agreed that drug traff...   \n",
       "4  Heidi said she wanted a beach wedding original...   \n",
       "\n",
       "                                             passage  \\\n",
       "0  By Mark Wilson for MailOnline For Callum McGre...   \n",
       "1  Editor's note: Julian E. Zelizer is a professo...   \n",
       "2  (CNN) -- My prized Penn State sweatshirt sits ...   \n",
       "3  (CNN) -- An isolated Indian tribe in Brazil se...   \n",
       "4  By Katy Winter PUBLISHED: 07:05 EST, 26 Februa...   \n",
       "\n",
       "                       entity  label  \n",
       "0                     Maribor   True  \n",
       "1                  New Jersey  False  \n",
       "2                    Sandusky   True  \n",
       "3  National Indian Foundation   True  \n",
       "4                       Heidi  False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.578545Z",
     "start_time": "2020-03-02T17:17:16.569136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2620\n",
       "True     2572\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from CSVs (alters depending on remove_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.591002Z",
     "start_time": "2020-03-02T17:17:16.579655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    False\n",
       "passage     False\n",
       "entity      False\n",
       "label       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.777220Z",
     "start_time": "2020-03-02T17:17:16.592103Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv(data_path/config.task/\"train.csv\",index=False)\n",
    "val.to_csv(data_path/config.task/\"val.csv\",index=False)\n",
    "test.to_csv(data_path/config.task/\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.865576Z",
     "start_time": "2020-03-02T17:17:16.779890Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/config.task/\"train.csv\")\n",
    "val = pd.read_csv(data_path/config.task/\"val.csv\")\n",
    "test = pd.read_csv(data_path/config.task/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.875049Z",
     "start_time": "2020-03-02T17:17:16.867177Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "val.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.882846Z",
     "start_time": "2020-03-02T17:17:16.876089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a Roberta specific DataBunch class\n",
    "class RobertaDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training Roberta\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n",
    "               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
    "               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:16.889552Z",
     "start_time": "2020-03-02T17:17:16.884046Z"
    }
   },
   "outputs": [],
   "source": [
    "class RobertaTextList(TextList):\n",
    "    _bunch = RobertaDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:22.651526Z",
     "start_time": "2020-03-02T17:17:16.890724Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the tokenizer and vocab processors\n",
    "processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n",
    "\n",
    "# creating our databunch \n",
    "data = ItemLists(\".\", RobertaTextList.from_df(train, \".\", cols=feat_cols, processor=processor),\n",
    "                      RobertaTextList.from_df(val, \".\", cols=feat_cols, processor=processor)\n",
    "                ) \\\n",
    "       .label_from_df(cols=label_cols, label_cls=CategoryList) \\\n",
    "       .add_test(RobertaTextList.from_df(test, \".\", cols=feat_cols, processor=processor)) \\\n",
    "       .databunch(bs=config.bs,pad_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:22.657167Z",
     "start_time": "2020-03-02T17:17:22.653040Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# defining our model architecture \n",
    "class RobertaForSequenceClassificationModel(nn.Module):\n",
    "    def __init__(self,num_labels=config.num_labels):\n",
    "        super(RobertaForSequenceClassificationModel,self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.roberta = RobertaForSequenceClassification.from_pretrained(config.roberta_model_name,num_labels= self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(input_ids, token_type_ids, attention_mask)\n",
    "        logits = outputs[0] \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:22.669763Z",
     "start_time": "2020-03-02T17:17:22.658304Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_score(input,target,eps:float=1e-9):\n",
    "    \"\"\"\n",
    "    Does not work. Provides faulty results during training.\n",
    "    \"\"\"\n",
    "    n = target.shape[0]\n",
    "    input = input.argmax(dim=-1).view(n,-1).float()\n",
    "    target = target.view(n,-1).float()\n",
    "    TP = (input*target).sum(0)\n",
    "    prec = TP / (input.sum(0)+eps)\n",
    "    rec = TP / (target.sum(0)+eps)\n",
    "    f1 = (2*prec*rec)/(prec+rec+eps)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:27.361504Z",
     "start_time": "2020-03-02T17:17:22.672352Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_model = RobertaForSequenceClassificationModel()\n",
    "\n",
    "learn = Learner(data, roberta_model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:27.364627Z",
     "start_time": "2020-03-02T17:17:27.362853Z"
    }
   },
   "outputs": [],
   "source": [
    "# run these to find optimal learing rates\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Untrained Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:27.380039Z",
     "start_time": "2020-03-02T17:17:27.365771Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    learn.model.roberta.eval()\n",
    "    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in data.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    ordered_preds = preds[reverse_sampler, :]\n",
    "    pred_values = np.argmax(ordered_preds, axis=1)\n",
    "    return ordered_preds, pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:27.391529Z",
     "start_time": "2020-03-02T17:17:27.381326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5046224961479199"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what % of the train labels are False\n",
    "(train.label==False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:17:27.397246Z",
     "start_time": "2020-03-02T17:17:27.392676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339060710194731"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what % of the val labels are False\n",
    "(val.label==False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:18:07.767578Z",
     "start_time": "2020-03-02T17:17:27.398463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339060710194731"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val preds\n",
    "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)\n",
    "# accuracy for valid with untrained model\n",
    "(pred_values == data.valid_ds.y.items).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:50.976589Z",
     "start_time": "2020-03-02T17:19:50.971470Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n",
    "learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:57.222040Z",
     "start_time": "2020-03-02T17:19:57.217386Z"
    }
   },
   "outputs": [],
   "source": [
    "# interpreting training results\n",
    "interp_train = ClassificationInterpretation.from_learner(learn, ds_type=DatasetType.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.769318Z",
     "start_time": "2020-03-02T17:19:05.607Z"
    }
   },
   "outputs": [],
   "source": [
    "interp_train.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.770097Z",
     "start_time": "2020-03-02T17:19:05.608Z"
    }
   },
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "conf_mat = interp_train.confusion_matrix()\n",
    "(conf_mat[0,0] + conf_mat[1,1]) / conf_mat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.771078Z",
     "start_time": "2020-03-02T17:19:05.609Z"
    }
   },
   "outputs": [],
   "source": [
    "# interpreting validation results\n",
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.771923Z",
     "start_time": "2020-03-02T17:19:05.611Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.772741Z",
     "start_time": "2020-03-02T17:19:05.612Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(conf_mat):\n",
    "    acc = (conf_mat[0,0] + conf_mat[1,1]) / conf_mat.sum()\n",
    "    rec = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1]) # TP / TP + FN\n",
    "    prec = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0]) # TP / TP + FP\n",
    "    f1 = 2*rec*prec/(rec+prec)\n",
    "    print(f\"acc: {acc}, recall: {rec}, precision: {prec}, f1: {f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.773701Z",
     "start_time": "2020-03-02T17:19:05.614Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize(interp.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.774567Z",
     "start_time": "2020-03-02T17:19:05.616Z"
    }
   },
   "outputs": [],
   "source": [
    "# val preds\n",
    "pred_values, preds = get_preds_as_nparray(DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:19:15.775432Z",
     "start_time": "2020-03-02T17:19:05.617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy for valid \n",
    "(preds == data.valid_ds.y.items).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Submission Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T05:57:26.469053Z",
     "start_time": "2020-03-03T05:56:46.335881Z"
    }
   },
   "outputs": [],
   "source": [
    "# test preds\n",
    "test_preds_values, test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T05:57:32.424124Z",
     "start_time": "2020-03-03T05:57:32.418071Z"
    }
   },
   "outputs": [],
   "source": [
    "test[\"pred_value\"] = list(test_preds_values)\n",
    "test[\"pred\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T05:57:35.853505Z",
     "start_time": "2020-03-03T05:57:35.693409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_best_idx(x):\n",
    "    x = np.vstack(x)\n",
    "    return np.argmax(x[:,-1])\n",
    "\n",
    "submission = test.groupby(\"idx\").agg({\"pred_value\":get_best_idx, \"entity\": lambda x: list(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T05:57:37.369090Z",
     "start_time": "2020-03-03T05:57:37.332298Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"pred_value\" in submission.columns:\n",
    "    submission[\"label\"] = submission.apply(lambda row: row[\"entity\"][row[\"pred_value\"]],1)\n",
    "    submission.drop([\"pred_value\",\"entity\"],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T05:57:37.954232Z",
     "start_time": "2020-03-03T05:57:37.946359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lester Holt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Union City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ollie Devoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Christians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "idx              \n",
       "13         Boston\n",
       "15    Lester Holt\n",
       "16     Union City\n",
       "23   Ollie Devoto\n",
       "29     Christians"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
