{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RoBERTa with Fastai - ReCoRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:37.559332Z",
     "start_time": "2019-10-04T22:47:36.596504Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.metrics import *\n",
    "from pytorch_transformers import RobertaTokenizer\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:37.564569Z",
     "start_time": "2019-10-04T22:47:37.561172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a config class to store task specific information\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:37.580240Z",
     "start_time": "2019-10-04T22:47:37.566023Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining our configuration\n",
    "\n",
    "config = Config(\n",
    "    task = \"ReCoRD\",\n",
    "#     remove_percent = None, # Set to a num between 0 and 1 to remove num% from training ds (for quicker training)\n",
    "    remove_percent = .4, # Set to None if not testing other this percetage will be removed from training ds\n",
    "    undersample = True, # will fix the class imbalance by undersampling\n",
    "    seq_len_check = True, # will remove all inputs over the max seq length (as opposed to truncating them)\n",
    "    seed = 2019,\n",
    "    roberta_model_name='roberta-base', # can also be exchanged with roberta-large \n",
    "    pad_idx = 0,\n",
    "    max_lr=1e-5,\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    bs=4, \n",
    "    max_seq_len=256, \n",
    "    num_labels = 3,\n",
    "    hidden_dropout_prob=.05,\n",
    "    hidden_size=768, # 1024 for roberta-large\n",
    "    start_tok = \"<s>\",\n",
    "    end_tok = \"</s>\",\n",
    "    mask_tok = \"<mask>\",\n",
    "    mark_fields=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:37.591489Z",
     "start_time": "2019-10-04T22:47:37.581762Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(\".\")\n",
    "data_path = path/\"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:37.599121Z",
     "start_time": "2019-10-04T22:47:37.592866Z"
    }
   },
   "outputs": [],
   "source": [
    "#load json object\n",
    "def record_parser(path_to_json, test=False):\n",
    "    with jsonlines.open(path_to_json) as f:\n",
    "        idx,passage,question,entity,label = [],[],[],[],[]\n",
    "        for obj in f:\n",
    "            text = obj[\"passage\"][\"text\"]\n",
    "            for q in obj['qas']:\n",
    "                if not test: answers = [a[\"text\"] for a in q[\"answers\"]] \n",
    "                for e in obj[\"passage\"][\"entities\"]:\n",
    "                    idx.append(obj[\"idx\"])\n",
    "                    passage.append(text)\n",
    "                    ques = q[\"query\"]#.replace(\"@placeholder\",config.mask_tok)\n",
    "                    question.append(ques)\n",
    "                    ent = text[e[\"start\"]:e[\"end\"]+1]\n",
    "                    entity.append(ent)\n",
    "                    label.append(ent in answers) if not test else label.append(None)\n",
    "    return pd.DataFrame({\"idx\":idx,\"passage\":passage,\"question\":question,\"entity\":entity,\"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.007091Z",
     "start_time": "2019-10-04T22:47:37.600318Z"
    }
   },
   "outputs": [],
   "source": [
    "train = record_parser(data_path/config.task/\"train.jsonl\")\n",
    "val = record_parser(data_path/config.task/\"val.jsonl\")\n",
    "test = record_parser(data_path/config.task/\"test.jsonl\",test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.018531Z",
     "start_time": "2019-10-04T22:47:41.009237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The harrowing stories of women and children lo...</td>\n",
       "      <td>The baby she gave birth to is her husbands and...</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The harrowing stories of women and children lo...</td>\n",
       "      <td>The baby she gave birth to is her husbands and...</td>\n",
       "      <td>Mariam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The harrowing stories of women and children lo...</td>\n",
       "      <td>The baby she gave birth to is her husbands and...</td>\n",
       "      <td>Badam Bagh</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The harrowing stories of women and children lo...</td>\n",
       "      <td>The baby she gave birth to is her husbands and...</td>\n",
       "      <td>Nuria</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The harrowing stories of women and children lo...</td>\n",
       "      <td>The baby she gave birth to is her husbands and...</td>\n",
       "      <td>Nuria</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            passage  \\\n",
       "0    0  The harrowing stories of women and children lo...   \n",
       "1    0  The harrowing stories of women and children lo...   \n",
       "2    0  The harrowing stories of women and children lo...   \n",
       "3    0  The harrowing stories of women and children lo...   \n",
       "4    0  The harrowing stories of women and children lo...   \n",
       "\n",
       "                                            question       entity  label  \n",
       "0  The baby she gave birth to is her husbands and...  Afghanistan  False  \n",
       "1  The baby she gave birth to is her husbands and...       Mariam  False  \n",
       "2  The baby she gave birth to is her husbands and...   Badam Bagh  False  \n",
       "3  The baby she gave birth to is her husbands and...        Nuria   True  \n",
       "4  The baby she gave birth to is her husbands and...        Nuria   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.037012Z",
     "start_time": "2019-10-04T22:47:41.020040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The harrowing stories of women and children locked up for so-called 'moral crimes' in Afghanistan's notorious female prison have been revealed after cameras were allowed inside. Mariam has been in Badam Bagh prison for three months after she shot a man who just raped her at gunpoint and then turned the weapon on herself - but she has yet to been charged. Nuria has eight months left to serve of her sentence for trying to divorce her husband. She gave birth in prison to her son and they share a cell together. Scroll down for video Nuria was jailed for trying to divorce her husband. Her son is one of 62 children living at Badam Bagh prison\\n@highlight\\nMost of the 202 Badam Bagh inmates are jailed for so-called 'moral crimes'\\n@highlight\\nCrimes include leaving their husbands or refusing an arrange marriage\\n@highlight\\n62 children live there and share cells with their mothers and five others\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.passage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.041602Z",
     "start_time": "2019-10-04T22:47:41.038329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The baby she gave birth to is her husbands and he has even offered to have the courts set her free if she returns, but @placeholder has refused.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.question[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.062649Z",
     "start_time": "2019-10-04T22:47:41.042925Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1537301\n",
       "True      259555\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.065974Z",
     "start_time": "2019-10-04T22:47:41.063872Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = [\"question\",\"passage\",\"entity\"]\n",
    "label_cols = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.075768Z",
     "start_time": "2019-10-04T22:47:41.067255Z"
    }
   },
   "outputs": [],
   "source": [
    "class FastAiRobertaTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n",
    "    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n",
    "        self._pretrained_tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len \n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self \n",
    "    def tokenizer(self, t:str) -> List[str]: \n",
    "        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n",
    "        if config.mark_fields:\n",
    "            sub = 2 # subtraction in totoal seq_length to be made due to adding spcl tokens\n",
    "            assert \"xxfld\" in t\n",
    "            t = t.replace(\"xxfld 1\",\"\") # remove the xxfld 1 special token from fastai\n",
    "            # converting fastai field sep token to Roberta\n",
    "            t = re.split(r'xxfld \\d+', t) \n",
    "            res = []\n",
    "            for i in range(len(t)-1): # loop over the number of additional fields and the Roberta sep\n",
    "                res += self._pretrained_tokenizer.tokenize(t[i]) + [config.end_tok]\n",
    "                sub += 1 # increase our subtractions since we added more spcl tokens\n",
    "            res += self._pretrained_tokenizer.tokenize(t[-1]) # add the last sequence\n",
    "            return [config.start_tok] + res[:self.max_seq_len - sub] + [config.end_tok] \n",
    "        \n",
    "        res = self._pretrained_tokenizer.tokenize(t)\n",
    "        return [config.start_tok] + res[:self.max_seq_len - sub] + [config.end_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.464469Z",
     "start_time": "2019-10-04T22:47:41.077097Z"
    }
   },
   "outputs": [],
   "source": [
    "# create fastai tokenizer for roberta\n",
    "roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n",
    "                             pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.575853Z",
     "start_time": "2019-10-04T22:47:41.465893Z"
    }
   },
   "outputs": [],
   "source": [
    "# create fastai vocabulary for roberta\n",
    "roberta_tok.save_vocabulary(path)\n",
    "\n",
    "with open('vocab.json', 'r') as f:\n",
    "    roberta_vocab_dict = json.load(f)\n",
    "    \n",
    "fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.581327Z",
     "start_time": "2019-10-04T22:47:41.577372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up pre-processors\n",
    "class RobertaTokenizeProcessor(TokenizeProcessor):\n",
    "    def __init__(self, tokenizer):\n",
    "         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False, mark_fields=config.mark_fields)\n",
    "\n",
    "class RobertaNumericalizeProcessor(NumericalizeProcessor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, vocab=fastai_roberta_vocab, **kwargs)\n",
    "\n",
    "\n",
    "def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
    "    \"\"\"\n",
    "    Constructing preprocessors for Roberta\n",
    "    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n",
    "    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n",
    "    \"\"\"\n",
    "    return [RobertaTokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(vocab=vocab)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:57:34.043098Z",
     "start_time": "2019-09-30T20:57:34.037768Z"
    }
   },
   "source": [
    "## Accounting for DF Size and Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:41.677397Z",
     "start_time": "2019-10-04T22:47:41.582549Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "def undersample(df):\n",
    "    rus = RandomUnderSampler(random_state=config.seed)\n",
    "    X_train, y_train = rus.fit_resample(df[feat_cols], df[label_cols])\n",
    "    res = pd.DataFrame(X_train)\n",
    "    res[\"label\"] = y_train\n",
    "    res.columns = df[[\"question\",\"passage\",\"entity\"]+[label_cols]].columns\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:42.515342Z",
     "start_time": "2019-10-04T22:47:41.679062Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.undersample: train = undersample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:42.630873Z",
     "start_time": "2019-10-04T22:47:42.517064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207644 of the training dataset is removed\n"
     ]
    }
   ],
   "source": [
    "# reduce df sizes if testing\n",
    "\n",
    "np.random.seed(config.seed)\n",
    "    \n",
    "if config.remove_percent: # if testing\n",
    "    print(int(train.shape[0]*config.remove_percent), \"of the training dataset is removed\")\n",
    "    \n",
    "    remove_percent = config.remove_percent\n",
    "    train_drop_indices = np.random.choice(train.index, int(train.shape[0]*remove_percent), replace=False)\n",
    "    train.drop(train_drop_indices, inplace=True)\n",
    "    \n",
    "    val_drop_indices = np.random.choice(val.index, int(val.shape[0]*remove_percent), replace=False)\n",
    "    val.drop(val_drop_indices, inplace=True)\n",
    "    \n",
    "    test_drop_indices = np.random.choice(test.index, int(test.shape[0]*remove_percent), replace=False)\n",
    "    test.drop(test_drop_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:42.635056Z",
     "start_time": "2019-10-04T22:47:42.632274Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_len_check(row):\n",
    "    seq_len = 1\n",
    "    for c in feat_cols:\n",
    "        seq_len += len(roberta_tok.tokenize(str(row[c]))) + 1    \n",
    "    return seq_len < (config.max_seq_len - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:42.649121Z",
     "start_time": "2019-10-04T22:47:42.636301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311466, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:47:36.625Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if config.seq_len_check:\n",
    "    train_in_range = train.apply(seq_len_check,axis=1)\n",
    "    val_in_range = val.apply(seq_len_check,axis=1)\n",
    "    test_in_range = test.apply(seq_len_check,axis=1)\n",
    "\n",
    "    print(\"dropping {} out of {} questions in train\".format(sum(~train_in_range),len(train)))\n",
    "    print(\"dropping {} out of {} questions in val\".format(sum(~val_in_range),len(val)))\n",
    "    print(\"dropping {} out of {} questions in test\".format(sum(~test_in_range),len(test)))\n",
    "\n",
    "    train = train[train_in_range]\n",
    "    val = val[val_in_range]\n",
    "    test = test[test_in_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:47:36.626Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training and val data\n",
    "train = train.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n",
    "val = val.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:47:36.628Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:47:36.630Z"
    }
   },
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from CSVs (.4 remove percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:53:24.863826Z",
     "start_time": "2019-10-05T03:53:24.833722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    False\n",
       "passage     False\n",
       "entity       True\n",
       "label       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:52:28.203586Z",
     "start_time": "2019-10-05T03:52:24.620870Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv(data_path/config.task/\"train.csv\",index=False)\n",
    "val.to_csv(data_path/config.task/\"val.csv\",index=False)\n",
    "test.to_csv(data_path/config.task/\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:52:37.964374Z",
     "start_time": "2019-10-05T03:52:36.704341Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/config.task/\"train.csv\")\n",
    "val = pd.read_csv(data_path/config.task/\"val.csv\")\n",
    "test = pd.read_csv(data_path/config.task/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:54:04.419877Z",
     "start_time": "2019-10-05T03:54:04.359620Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "val.dropna(inplace=True)\n",
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:54:07.439438Z",
     "start_time": "2019-10-05T03:54:07.430456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a Roberta specific DataBunch class\n",
    "class RobertaDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training Roberta\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n",
    "               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
    "               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:54:07.844009Z",
     "start_time": "2019-10-05T03:54:07.839603Z"
    }
   },
   "outputs": [],
   "source": [
    "class RobertaTextList(TextList):\n",
    "    _bunch = RobertaDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:55:13.399550Z",
     "start_time": "2019-10-05T03:54:07.845340Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the tokenizer and vocab processors\n",
    "processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n",
    "\n",
    "# creating our databunch \n",
    "data = ItemLists(\".\", RobertaTextList.from_df(train, \".\", cols=feat_cols, processor=processor),\n",
    "                      RobertaTextList.from_df(val, \".\", cols=feat_cols, processor=processor)\n",
    "                ) \\\n",
    "       .label_from_df(cols=label_cols, label_cls=CategoryList) \\\n",
    "       .add_test(RobertaTextList.from_df(test, \".\", cols=feat_cols, processor=processor)) \\\n",
    "       .databunch(bs=config.bs,pad_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:29.873280Z",
     "start_time": "2019-10-05T03:56:29.866730Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import RobertaForSequenceClassification\n",
    "\n",
    "# defining our model architecture \n",
    "class RobertaForSequenceClassificationModel(nn.Module):\n",
    "    def __init__(self,num_labels=config.num_labels):\n",
    "        super(RobertaForSequenceClassificationModel,self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.roberta = RobertaForSequenceClassification.from_pretrained(config.roberta_model_name,num_labels= self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(input_ids, token_type_ids, attention_mask)\n",
    "        logits = outputs[0] \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:32.435914Z",
     "start_time": "2019-10-05T03:56:32.429526Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_score(input,target,eps:float=1e-9):\n",
    "    n = target.shape[0]\n",
    "    input = input.argmax(dim=-1).view(n,-1).float()\n",
    "    target = target.view(n,-1).float()\n",
    "    TP = (input*target).sum(0)\n",
    "    prec = TP / (input.sum(0)+eps)\n",
    "    rec = TP / (target.sum(0)+eps)\n",
    "    f1 = (2*prec*rec)/(prec+rec+eps)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:37.048754Z",
     "start_time": "2019-10-05T03:56:33.454110Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_model = RobertaForSequenceClassificationModel()\n",
    "\n",
    "learn = Learner(data, roberta_model, metrics=[accuracy, f_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:47:36.641Z"
    }
   },
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Untrained Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:40.846811Z",
     "start_time": "2019-10-05T03:56:40.843391Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    learn.model.roberta.eval()\n",
    "    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in data.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    ordered_preds = preds[reverse_sampler, :]\n",
    "    pred_values = np.argmax(ordered_preds, axis=1)\n",
    "    return ordered_preds, pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:42.787163Z",
     "start_time": "2019-10-05T03:56:42.783417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4863387519312152"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what % of the train labels are False\n",
    "(train.label==False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:56:44.314928Z",
     "start_time": "2019-10-05T03:56:44.309085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120193016836293"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what % of the val labels are False\n",
    "(val.label==False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T13:36:20.463733Z",
     "start_time": "2019-10-05T13:36:20.461780Z"
    }
   },
   "outputs": [],
   "source": [
    "# val preds\n",
    "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)\n",
    "# accuracy for valid with untrained model\n",
    "(pred_values == data.valid_ds.y.items).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T10:38:20.914282Z",
     "start_time": "2019-10-05T03:57:04.382422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.327451</td>\n",
       "      <td>0.392896</td>\n",
       "      <td>0.831995</td>\n",
       "      <td>0.229506</td>\n",
       "      <td>3:20:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.177669</td>\n",
       "      <td>0.300788</td>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.235516</td>\n",
       "      <td>3:20:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n",
    "learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T12:44:28.989259Z",
     "start_time": "2019-10-05T12:44:28.983873Z"
    }
   },
   "outputs": [],
   "source": [
    "# interpreting training results\n",
    "interp_train = ClassificationInterpretation.from_learner(learn, ds_type=DatasetType.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:48:11.551402Z",
     "start_time": "2019-10-04T22:47:36.653Z"
    }
   },
   "outputs": [],
   "source": [
    "interp_train.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:48:11.552724Z",
     "start_time": "2019-10-04T22:47:36.655Z"
    }
   },
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "conf_mat = interp_train.confusion_matrix()\n",
    "(conf_mat[0,0] + conf_mat[1,1]) / conf_mat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T13:04:11.432542Z",
     "start_time": "2019-10-05T12:45:14.858435Z"
    }
   },
   "outputs": [],
   "source": [
    "# interpreting validation results\n",
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T13:04:13.462348Z",
     "start_time": "2019-10-05T13:04:11.434029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T13:38:30.712025Z",
     "start_time": "2019-10-05T13:38:30.708514Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(conf_mat):\n",
    "    acc = (conf_mat[0,0] + conf_mat[1,1]) / conf_mat.sum()\n",
    "    rec = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1]) # TP / TP + FN\n",
    "    prec = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0]) # TP / TP + FP\n",
    "    f1 = 2*rec*prec/(rec+prec)\n",
    "    print(f\"acc: {acc}, recall: {rec}, precision: {prec}, f1: {f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T13:38:33.169745Z",
     "start_time": "2019-10-05T13:38:31.411294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8894999683924395, recall: 0.6467395642110304, precision: 0.9083062436946531, f1: 0.7555244755244755\n"
     ]
    }
   ],
   "source": [
    "summarize(interp.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:48:11.558081Z",
     "start_time": "2019-10-04T22:47:36.661Z"
    }
   },
   "outputs": [],
   "source": [
    "# val preds\n",
    "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:48:11.559419Z",
     "start_time": "2019-10-04T22:47:36.663Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy for valid \n",
    "(pred_values == data.valid_ds.y.items).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T03:48:11.560912Z",
     "start_time": "2019-10-04T22:47:36.664Z"
    }
   },
   "outputs": [],
   "source": [
    "# test preds\n",
    "test_preds, test_pred_values = get_preds_as_nparray(DatasetType.Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
